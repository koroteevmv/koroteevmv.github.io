---
title: "Как пользователи воспринимают контент, сгенерированный нейросетью?"
categories:
  - scipop
tags:
  - article
  - ai
  - ai_regulation
toc: false
excerpt: "Аналитическая заметка о новейших исследованиях в области восприятия ИИ-контента. Как ваши пользователи отнесутся к тому, что вы используете нейросети для массовой генерации контента для них? Читайте подборку мнений и результатов исследований."
---

По оценкам исследователей, уже более 50% всего объема контента в интернете создается полностью или частично с применением генеративного искусственного интеллекта. Хорошо это или плохо, мы в любом случае потребляем такой «искусственный» контент. Да и многие компании сознательно привлекают ресурсы современных нейросетей для массового создания визуальных элементов, текстов, баннеров, постов в социальных сетях, сценариев для роликов, и так далее. Ведь это так быстро, просто и дешево. Но улучшает ли сгенерированный контент пользовательский опыт?

Недавнее количественное [исследование](https://vk.com/away.php?to=https%3A%2F%2Fmitsloan.mit.edu%2Fideas-made-to-matter%2Fstudy-gauges-how-people-perceive-ai-created-content&cc_key=) MIT (Ю. Чжан и Р. Гослин) призвано оценить эффекты восприятия разного типа контента человеком. Для этого исследователи поставили два типа задач: составить маркетинговое описание определенного товара и составить маркетинговую стратегию вокруг довольно общепринятого императива (например, «надо есть меньше вредной пищи»). Решением каждой задачи был определенный контент, который затем оценивали в фокус-группах. Этот контент был разделен на четыре уровня автоматизации:

1. Созданный человеком - профессиональный маркетолог полностью составлял текст.
1. Обработанный человеком - модели ИИ использовались для генерации первоначальных идей, которые человек затем превращал в финальный продукт.
1. Обработанный ИИ - наоборот, человек сочинял черновик текста, который затем передавался искусственному интеллекту для финализации.
1. Созданный ИИ - модель ChatGPT-4 полностью генерировала финальный продукт.

Люди, оценивавшие качество контента были разделены на три группы. Первые ничего не знали о процессе и методах создания контента. Вторые познакомились с четырьмя уровнями выше, но не знали, какой продукт как был создан. И, наконец, респонденты из третьей группы имели полную информацию о том, как был создан каждый продукт.

Исследователи выявили два главных эффекта. Пользователи, не знавшие происхождение контента, отдавали предпочтение продукту, сгенерированному искусственно. Это подтверждает тот факт, что современные модели могут превосходить человека в определенных задачах.

Второй же эффект авторы исследования даже вынесли в заголовок своей статьи: «[Human Favoritism, Not AI Aversion](https://vk.com/away.php?to=https%3A%2F%2Fpapers.ssrn.com%2Fsol3%2Fpapers.cfm%3Fabstract_id%3D4453958&cc_key=)»: если люди знают происхождение контента, они будут больше предпочитать продукт, созданный человеком. При этом оценка качества «искусственного» контента не снижается

> Самый прямой вывод заключается в том, что потребители действительно не возражают против контента, создаваемого с помощью искусственного интеллекта. В целом они не возражают против этого”, - сказал Чжан. “В то же время, есть большая польза в том, чтобы знать, что где—то на этом пути задействованы люди - что их отпечатки пальцев присутствуют. Компаниям не следует стремиться к полной автоматизации процесса, исключая людей из него.

Авторы подчеркивают, что выводы их исследования не носят окончательный характер, а лишь призваны подстегнуть компании, использующие ИИ для создания контента, проводить подобные исследования в своей предметной области.

Еще одно исследование, посвященное оценке восприятия текстового контента, было [проведено](https://digikogu.taltech.ee/et/Download/10c04466-2d22-433a-a6ee-21b44013bb6b/Tehisintellektiloodudsisutoimivussisuturunduse.pdf) в Таллинском технологическом университете.

Несмотря на отсутствие существенных различий в воспринимаемой читателями эффективности, качестве контента и доверии к публикациям, блог, созданный искусственным интеллектом, показал лучшие результаты, чем блог, написанный человеком, с точки зрения уровня вовлеченности.

Что касается посадочных страниц, то контент, написанный человеком, превзошел контент, созданный искусственным интеллектом, и набрал на 97,37% более высокий уровень вовлеченности, что делает его более успешным в привлечении внимания и желаний аудитории.

С другой стороны, результаты экспериментов с электронной почтой показали, что контент с искусственным интеллектом более эффективен в привлечении внимания и мотивации пользователей к желаемому действию, но были безрезультатными из-за небольшого количества и требуют дальнейшего изучения с использованием большего объема выборки. Опрос профессиональных авторов о восприятии эффективности, качества контента, достоверности и ограничений показал, что авторы считают контент, созданный с помощью искусственного интеллекта, эффективным, высококачественным и заслуживающим доверия, признавая при этом его ограничения.

Практически эта информация может помочь маркетологам и бизнес-менеджерам принимать обоснованные решения о включении контента, созданного с помощью искусственного интеллекта, в общую контент-стратегию и его возможном влиянии.

Будущие исследования могут дополнительно изучить потенциал контента, генерируемого искусственным интеллектом, в различных типах контента и контекстах, а также потенциальные сдерживающие факторы, которые могут повлиять на его производительность.

Исследование университета Ченная (Индия) [выявило](https://www.webology.org/data-cms/articles/20220324051907pmwebology%2019%20(2)%20-%20458%20pdf.pdf) разницу в восприятии рекламных сообщений и брендировании люксовых товаров, созданных человеком и машиной. В этом исследовании 69% респондентов предпочли контент, сгенерированный с помощью нейросетей.

При этом авторы отмечают, что использовали уже готовый контент с высокой степенью эффективности и результаты исследования могли быть совершенно другими при анализе контента разного уровня зрелости.

Эффективность моделей генерации изображений подтверждает и исследование, [проведенное](https://arxiv.org/pdf/2304.13023.pdf) совместно Шанхайским, Гонконгским и Сиднейскими университетами. В нем авторы обнаружили, что люди все чаще ошибаются в распознавании сгенерированного контента. Они предлагали пользователям определить, какие изображения были реально сделанными фотографиями, а какие - фотореалистичными сгенерированными изображениями.Оказалось, что люди ошибаются в 38,7% случаев.

Исследователи из Стэнфорда и Корнуэлла [отмечают](http://library.usc.edu.ph/ACM/CHI2019/1proc/paper239.pdf), что знание или даже подозрение, что текст был сгенерирован искусственным интеллектом, значительно влияет на доверие к нему читателей.

В этом исследовании авторы оценивали восприятие отзывов на лоты на сайте Airbnb. Результаты получились однозначными: чем больше респондент верит, что отзывы были сгенерированы, тем меньше он проявляет доверия к соответствующему лоту.

> Наши результаты показывают устойчивую тенденцию: в таком мире со смешанным исходным кодом знание или даже подозрение в том, что профиль является репликантом (т.е. сгенерированным искусственным интеллектом), приводит к недоверию. Текущая работа прояснила условия, при которых возникает эффект репликанта, и предоставила доказательства того, что он зависит от значимости источника.

Это исследование выявило еще один интересный факт: мнение пользователей об искусственности контента основано не столько на рациональном анализе, сколько на предрассудках и субъективных теориях о том, как должен выглядеть сгенерированный текст:

> Неофициальный анализ открытых ответов на наши исследования дает подсказки о том, какие факторы сделали профили похожими. Например, разговорный стиль письма и личные данные воспринимаются как свидетельство человеческого письма, в то время как маркированные “списки нерелевантной информации”, как выразился один участник, делают профили более “искусственными”.

Очень многие исследователи отмечают негативные стороны широкого использования генеративного искусственного интеллекта для массового создания контента. Среди проблем, которые [отмечают](https://aicontentfy.com/en/blog/impact-of-ai-on-content-authenticity) исследователи:

1. Фейковые новости и сгенерированная ИИ пропаганда.
1. Эрозия истины и снижение доверия к информации и ее источникам.
1. Возможность использования ИИ для цензуры и контроля над информацией.
1. Наполнение Интернета [«мусорным»](https://www.technologyreview.com/2023/06/26/1075504/junk-websites-filled-with-ai-generated-text-are-pulling-in-money-from-programmatic-ads/) контентом.
1. Серые схемы заработка и рекламные пирамиды, основанные на ИИ-контенте.

Отсюда важность дискуссий о регуляции ИИ, этике использования искусственного интеллекта. Почти все исследователи сходятся на мысли, что необходимо принять меры по явному [маркированию](https://kontent.ai/blog/emerging-best-practices-for-disclosing-ai-generated-content/) контента, произведенного с помощью ИИ.

Поможет ли это? Или приведет к ИИ-слепоте? Данный вопрос остается недоисследованным.