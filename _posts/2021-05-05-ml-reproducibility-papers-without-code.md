---
title: "Воспроизводимость исследований в области машинного обучения"
classes: None
categories:
  - scipop
  - translation
  - article
tags:
  - Кейсы ИИ
  - ИИ в науке
toc: true
excerpt: "Смотрите, к чему приводит палочная система оценки результативности научных исследований. Кризис воспроизводимости обсуждается серьезно. И уже довольно понятно, что большинство научных статей, написанных ради галочки из-под палки - полный мусор. А этот мусор сильно загрязняет информационное пространство и затрудняет поиск нужной информации."
---


[Оригинал](https://thenextweb.com/news/list-non-reproducible-research-machine-learning-papers-syndication)

14 февраля исследователь, разочарованный воспроизведением результатов исследовательской работы по машинному обучению, открыл учетную запись Reddit под именем ContributionSecure14 и разместил [субреддит r/MachineLearning](https://www.reddit.com/r/MachineLearning/comments/lk03ef/d_list_of_unreproducible_papers/): «Я только что потратил неделю на реализацию метода из статьи в качестве основы для своего исследования и мне так и не удалось воспроизвести результаты. Я понял сегодня после того, как немного погуглил, что некоторые другие также не смогли воспроизвести результаты. Есть ли список таких бумаг? Это сэкономит людям много времени и сил ».

Этот пост задел других пользователей r/MachineLearning, крупнейшего Reddit-сообщества машинного обучения.

«Проще составить список воспроизводимых…», - ответил один пользователь.

«Вероятно, 50% -75% всех бумаг невоспроизводимы. Это печально, но это правда », - написал другой пользователь. «Подумайте об этом, большинство статей оптимизированы для участия в конференции. Чаще всего авторы знают, что доклад, который они пытаются представить на конференции, не очень хорош! Поэтому им не нужно беспокоиться о воспроизводимости, потому что никто не будет пытаться их воспроизвести».

Несколько других пользователей разместили ссылки на документы по машинному обучению, которые им не удалось реализовать, и выразили разочарование по поводу того, что реализация кода не является требованием на конференциях по машинному обучению.

На следующий день ContributionSecure14 создал «[Документы без кода](https://www.paperswithoutcode.com/)» - веб-сайт, который призван создать централизованный список документов по машинному обучению, которые невозможно реализовать.

«Я не уверен, хорошая это или плохая идея, но я подумал, что было бы полезно собрать список статей, которые люди пытались воспроизвести, но потерпели неудачу», - ContributionSecure14 [написал на r/MachineLearning](https://www.reddit.com/r/MachineLearning/comments/lk8ad0/p_burnedpapers_where_unreproducible_papers_come/). «Это даст авторам возможность либо выпустить свой код, либо предоставить ссылки, либо отозвать статью. Я надеюсь, что это будет стимулировать более здоровую культуру исследования машинного обучения, не публиковать невоспроизводимые работы».


## Воспроизведение результатов статей о машинном обучении


![alt_text](/assets/images/2021-05-05/image1.jpg "image_tooltip")


Исследователи регулярно публикуют статьи на таких онлайн-платформах, как arXiv и OpenReview. В этих документах описываются концепции и методы, которые обсуждают новые проблемы в системах машинного обучения или вводят новые способы решения известных проблем. Многие из этих статей находят свое отражение в основных конференциях по искусственному интеллекту, таких как NeurIPS, ICML, ICLR и CVPR.

Наличие исходного кода, сопровождающего исследовательскую работу, очень помогает в проверке правильности техники машинного обучения и построении на ней. Но это не является требованием для конференций по машинному обучению. В результате многим студентам и исследователям, читающим эти статьи, сложно воспроизвести свои результаты.

«Невоспроизводимая работа тратит время и силы исследователей, и авторы должны стремиться к тому, чтобы существовала хотя бы одна публичная реализация своей работы», - сказал ContributionSecure14, пожелавший остаться неизвестным. «Публикация статьи с эмпирическими результатами в открытом доступе бессмысленна, если другие не могут основываться на бумаге или использовать ее в качестве основы».

Но ContributionSecure14 также признает, что иногда у исследователей машинного обучения есть законные причины не выпускать свой код. Например, некоторые авторы могут обучать свои модели во внутренней инфраструктуре или использовать большие внутренние наборы данных для предварительного обучения. В таких случаях исследователи не могут публиковать код или данные вместе со своей статьей из-за политики компании.

«Если авторы из-за таких обстоятельств публикуют статью без кода, я лично считаю, что они несут академическую ответственность за тесное сотрудничество с другими исследователями, пытающимися воспроизвести их статью», - говорит ContributionSecure14. «Нет смысла публиковать статью в открытом доступе, если другие не могут использовать ее. Должна быть по крайней мере одна общедоступная эталонная реализация, которую другие могли бы использовать в качестве основы».

В некоторых случаях, даже если авторы публикуют и исходный код, и данные в своей статье, другим исследователям машинного обучения все еще трудно воспроизвести результаты. Это может быть связано с разными причинами. Например, авторы могут выбрать лучшие результаты из нескольких экспериментов и представить их как новейшие достижения. В других случаях исследователи могли использовать такие приемы, как настройка параметров своей модели машинного обучения на набор тестовых данных, чтобы улучшить результаты. В таких случаях, даже если результаты воспроизводимы, они не имеют отношения к делу, потому что модель машинного обучения была адаптирована к конкретным условиям и не будет хорошо работать с ранее невидимыми данными.

«Я думаю, что необходимо иметь воспроизводимый код в качестве предварительного условия для независимой проверки достоверности результатов, заявленных в статье, но [одного кода] недостаточно», - сказал ContributionSecure14.


## Усилия по воспроизводимости машинного обучения.


![alt_text](/assets/images/2021-05-05/image4.jpg "image_tooltip")

[Papers With Code](https://paperswithcode.com/) предоставляет репозиторий реализации кода для научных статей.

Проблема воспроизводимости не ограничивается небольшими исследовательскими группами по машинному обучению. Даже крупные технологические компании, которые ежегодно тратят миллионы долларов на исследования ИИ, часто не могут подтвердить результаты своих работ. В октябре 2020 года группа из 31 ученого написала [совместную статью в Nature](https://www.nature.com/articles/s41586-020-2766-y.epdf?sharing_token=IKEjJGNcs02x-u2ZebGiatRgN0jAjWel9jnR3ZoTv0M3qEeZVaYZS89U0ri_i4YI_lJ0an-lE15Ncv2e1v5F7I2jYVuc7_mR1WrnlDjpWJ6ANzSjO0KJiERmpzE097VzbFgywD7RRHVOYg305JycIUX7UQDWkLlgHtsoU72ppNwLIpOTA4XtFD65GIE64GKpAvFnn8C8JtrXUeYFG6wdpx21AQI3t-jw7hysz0zy-qQ%3D&tracking_referrer=www.technologyreview.com), критикуя отсутствие прозрачности и воспроизводимости в статье об использовании ИИ в медицинской визуализации, опубликованной группой исследователей ИИ в Google. «[Отсутствие] достаточно документированных методов и компьютерного кода, лежащих в основе исследования, эффективно подрывает его научную ценность. Этот недостаток ограничивает доказательства, необходимые другим для проспективной проверки и клинического применения таких технологий », - пишут авторы. «Научный прогресс зависит от способности независимых исследователей тщательно анализировать результаты исследования, воспроизводить основные результаты исследования, используя его материалы, и использовать их в будущих исследованиях».

В последние годы наблюдается рост внимания к кризису воспроизводимости ИИ. Примечательная работа в этом отношении включает усилия Джоэл Пино, ученого по машинному обучению из Монреальского университета Макгилла и Facebook AI, которая на таких конференциях, как NeurIPS, настаивает на прозрачности и воспроизводимости исследований машинного обучения.

«Лучшая воспроизводимость означает, что со статьей будет проще работать. Часто процесс рецензирования бывает коротким и ограниченным, и истинное влияние статьи мы видим гораздо позже. Документ продолжает жить, и как сообщество у нас есть шанс продолжить работу, изучить код и критически оценить свой вклад», - Пино говорил [Nature](https://www.nature.com/articles/d41586-019-03895-5) в интервью в 2019 году.

В NeurIPS Пино помогал в разработке стандартов и процессов, которые могут помочь исследователям и рецензентам оценить воспроизводимость статей о машинном обучении. Ее усилия привели к увеличению количества отправляемых кодов и данных в NeurIPS.

Еще один интересный проект - это «[Документы с кодом»](https://paperswithcode.com/) (отсюда и название «Документы без кода»), веб-сайт, который предоставляет реализации для научных исследований, опубликованных и представленных в различных местах. В Papers With Code в настоящее время реализовано более 40 000 исследовательских работ по машинному обучению.

«PapersWithCode играет важную роль в выделении воспроизводимых документов. Однако это не решает проблему невоспроизводимых документов», - говорится в сообщении ContributionSecure14.

Когда исследовательская работа по машинному обучению не включает код реализации, другие исследователи, которые ее читают, должны попытаться реализовать его самостоятельно - а это нетривиальный процесс, который может занять несколько недель и в конечном итоге привести к неудаче.

«Если им не удастся реализовать это успешно, они могут связаться с авторами (которые могут не ответить) или просто отказаться от этого», - сказал ContributionSecure14. «Это может случиться с несколькими исследователями, которые не знают о предыдущих или текущих попытках воспроизвести статью, что приведет к коллективной потере продуктивности в течение многих недель».


## Документы без кода


![alt_text](/assets/images/2021-05-05/image2.jpg "image_tooltip")
Документы без кода отслеживают документы по машинному обучению, которые имеют невоспроизводимые результаты.

Документы без кода включают [страницу](https://www.paperswithoutcode.com/) для отправки, где исследователи могут отправлять невоспроизводимые статьи о машинном обучении вместе с деталями своих усилий, например, сколько времени они потратили на попытки воспроизвести результаты. Если заявка действительна, Papers Without Code свяжется с первоначальными авторами статьи и запросит разъяснения или публикацию деталей реализации. Если авторы не ответят вовремя, статья будет добавлена ​​в список [невоспроизводимых статей по машинному обучению](https://papers.paperswithoutcode.com/).

«PapersWithoutCode решает проблему централизации информации о предыдущих или текущих попытках воспроизвести статью и позволяет исследователям (включая первоначального автора) объединиться и реализовать общедоступную реализацию», - сказал ContributionSecure14. «Как только статья будет успешно воспроизведена, ее можно будет опубликовать на PapersWithCode или GitHub, где ее смогут использовать другие исследователи. В этом смысле я бы сказал, что цели PapersWithoutCode синергичны с целями PapersWithCode и сообщества машинного обучения в целом».

Есть надежда, что «Документы без кода» помогут создать культуру, стимулирующую воспроизводимость исследований в области машинного обучения. На данный момент на сайт поступило более 10 запросов, и один автор уже пообещал загрузить свой код.

«Я понимаю, что это может быть спорным вопросом в академических кругах, и главным приоритетом является защита репутации авторов при обслуживании более широкого сообщества машинного обучения», - сказал ContributionSecure14.

Документы без кода могут стать центром диалога между первоначальными авторами статей о машинном обучении и исследователями, которые пытаются воспроизвести свою работу.

«Вместо статичного списка невоспроизводимых работ мы надеемся создать среду, в которой исследователи могут сотрудничать для воспроизведения статьи», - сказал ContributionSecure14.


## Воспроизводимые исследования в области машинного обучения

![alt_text](/assets/images/2021-05-05/image3.jpg "image_tooltip")


Создание культуры воспроизводимой работы в области машинного обучения потребует согласованных усилий всех исследователей и ученых.

Например, если вы работаете над исследованием, основанным на работе, выполненной в другой статье, вам следует самостоятельно опробовать код или модель машинного обучения.

«Не основывайтесь на утверждениях или «выводах», которые потенциально могут быть необоснованными только потому, что об этом говорится в документе», - говорит ContributionSecure14, добавляя, что сюда входят статьи из крупных лабораторий или работы, которые были приняты на авторитетной конференции.

Еще один хороший ресурс - это «[Контрольный список воспроизводимости машинного обучения»](https://www.cs.mcgill.ca/~jpineau/ReproducibilityChecklist.pdf) профессора Пино. Контрольный список содержит четкие рекомендации о том, как сделать описание, код и данные статьи о машинном обучении понятными и воспроизводимыми для других исследователей.

ContributionSecure14 считает, что исследователи машинного обучения могут сыграть решающую роль в продвижении культуры воспроизводимости.

«Публикация оказывается под сильным давлением за счет академической глубины и воспроизводимости, и не так много сдержек и противовесов, чтобы предотвратить такое поведение», - сказал ContributionSecure14. «Это изменится только в том случае, если нынешнее и будущее поколение исследователей машинного обучения будет отдавать приоритет качеству над количеством в своих собственных исследованиях».
